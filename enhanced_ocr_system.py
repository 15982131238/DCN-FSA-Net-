#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆOCRè½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ - å¤šé‡æ£€æµ‹ç­–ç•¥ + æ™ºèƒ½ fallback
ç¡®ä¿åœ¨å„ç§æƒ…å†µä¸‹éƒ½èƒ½å‡†ç¡®è¯†åˆ«è½¦ç‰Œ
"""

import os
import sys
import logging
import time
import json
import sqlite3
import re
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from datetime import datetime
import io

import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageEnhance, ImageFilter, ImageOps
import cv2
import torch
import torch.nn as nn
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn
from starlette.middleware.cors import CORSMiddleware

# å°è¯•å¯¼å…¥OCRåº“
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
    print("Tesseract OCRå·²åŠ è½½")
except ImportError:
    TESSERACT_AVAILABLE = False
    print("Tesseract OCRä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨OpenCVè¿›è¡Œæ–‡å­—æ£€æµ‹")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(title="å¢å¼ºç‰ˆOCRè½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ", version="8.0.0")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")

# è½¦ç‰Œå­—ç¬¦é›†
PLATE_PROVINCES = "äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†"
PLATE_LETTERS = "ABCDEFGHJKLMNPQRSTUVWXYZ"
PLATE_NUMBERS = "0123456789"

class EnhancedOCRRecognizer:
    """å¢å¼ºç‰ˆOCRè¯†åˆ«å™¨ - å¤šé‡æ£€æµ‹ç­–ç•¥"""

    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.tesseract_available = TESSERACT_AVAILABLE
        logger.info(f"åˆå§‹åŒ–å¢å¼ºç‰ˆOCRè¯†åˆ«å™¨ï¼Œè®¾å¤‡: {self.device}")
        logger.info(f"Tesseractå¯ç”¨: {self.tesseract_available}")

    def comprehensive_preprocess(self, image: Image.Image) -> Tuple[Dict[str, np.ndarray], np.ndarray]:
        """å…¨é¢çš„å›¾åƒé¢„å¤„ç†"""
        # è½¬æ¢ä¸ºOpenCVæ ¼å¼
        cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

        # è°ƒæ•´å¤§å°ï¼Œä¿æŒå®½é«˜æ¯”
        height, width = cv_image.shape[:2]
        max_size = 1600  # å¢åŠ æœ€å¤§å°ºå¯¸ä»¥æé«˜æ£€æµ‹ç‡
        if max(width, height) > max_size:
            scale = max_size / max(width, height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            cv_image = cv2.resize(cv_image, (new_width, new_height))

        # å¤šç§é¢„å¤„ç†æ–¹æ³•
        results = {}

        # 1. æ ‡å‡†ç°åº¦åŒ–
        gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
        results['gray'] = gray

        # 2. ç›´æ–¹å›¾å‡è¡¡åŒ–
        equalized = cv2.equalizeHist(gray)
        results['equalized'] = equalized

        # 3. CLAHE
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
        clahe_result = clahe.apply(gray)
        results['clahe'] = clahe_result

        # 4. é«˜æ–¯æ¨¡ç³Š
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        results['blurred'] = blurred

        # 5. è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(gray, 50, 150)
        results['edges'] = edges

        # 6. è‡ªé€‚åº”é˜ˆå€¼
        adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        results['adaptive'] = adaptive

        # 7. å¤§æ´¥æ³•
        _, otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        results['otsu'] = otsu

        # 8. å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((3, 3), np.uint8)
        morph = cv2.morphologyEx(otsu, cv2.MORPH_CLOSE, kernel)
        results['morph'] = morph

        # 9. å¼€è¿ç®—
        opening = cv2.morphologyEx(otsu, cv2.MORPH_OPEN, kernel)
        results['opening'] = opening

        # 10. é¡¶å¸½å˜æ¢
        tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)
        results['tophat'] = tophat

        # 11. é»‘å¸½å˜æ¢
        blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)
        results['blackhat'] = blackhat

        # 12. æ¢¯åº¦å˜æ¢
        gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)
        results['gradient'] = gradient

        return results, cv_image

    def detect_license_plates_comprehensive(self, image: np.ndarray, processed_images: Dict[str, np.ndarray]) -> List[Tuple[np.ndarray, str]]:
        """ç»¼åˆè½¦ç‰Œæ£€æµ‹ç­–ç•¥"""
        all_plates = []

        # ç­–ç•¥1ï¼šåŸºäºè½®å»“æ£€æµ‹
        plates_contour = self.detect_by_contours(processed_images)
        all_plates.extend([(plate, 'contour') for plate in plates_contour])

        # ç­–ç•¥2ï¼šåŸºäºé¢œè‰²æ£€æµ‹
        plates_color = self.detect_by_color(image)
        all_plates.extend([(plate, 'color') for plate in plates_color])

        # ç­–ç•¥3ï¼šåŸºäºè¾¹ç¼˜æ£€æµ‹
        plates_edge = self.detect_by_edges(processed_images)
        all_plates.extend([(plate, 'edge') for plate in plates_edge])

        # ç­–ç•¥4ï¼šåŸºäºå½¢æ€å­¦æ“ä½œ
        plates_morph = self.detect_by_morphology(processed_images)
        all_plates.extend([(plate, 'morph') for plate in plates_morph])

        # ç­–ç•¥5ï¼šåŸºäºæ»‘åŠ¨çª—å£
        plates_window = self.detect_by_sliding_window(image)
        all_plates.extend([(plate, 'window') for plate in plates_window])

        return all_plates

    def detect_by_contours(self, processed_images: Dict[str, np.ndarray]) -> List[np.ndarray]:
        """åŸºäºè½®å»“æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        # å°è¯•å¤šç§é¢„å¤„ç†å›¾åƒ
        for method_name in ['morph', 'otsu', 'adaptive', 'clahe']:
            if method_name not in processed_images:
                continue

            image = processed_images[method_name]

            # è°ƒæ•´é˜ˆå€¼å‚æ•°
            if method_name == 'adaptive':
                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            else:
                _, binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for contour in contours:
                # è®¡ç®—è½®å»“é¢ç§¯
                area = cv2.contourArea(contour)

                # æ›´å®½æ¾çš„é¢ç§¯è¿‡æ»¤
                if area < 200:
                    continue

                # è®¡ç®—è¾¹ç•ŒçŸ©å½¢
                x, y, w, h = cv2.boundingRect(contour)

                # æ›´å®½æ¾çš„å®½é«˜æ¯”è¿‡æ»¤
                aspect_ratio = w / h
                if aspect_ratio < 1.0 or aspect_ratio > 8.0:
                    continue

                # æå–å€™é€‰åŒºåŸŸ
                plate_roi = image[y:y+h, x:x+w]

                # ç¡®ä¿åŒºåŸŸå¤§å°åˆç†
                if plate_roi.shape[0] < 10 or plate_roi.shape[1] < 30:
                    continue

                plates.append(plate_roi)

        return plates

    def detect_by_color(self, image: np.ndarray) -> List[np.ndarray]:
        """åŸºäºé¢œè‰²æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        # è“è‰²è½¦ç‰ŒèŒƒå›´
        lower_blue = np.array([100, 80, 46])
        upper_blue = np.array([124, 255, 255])
        blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)

        # é»„è‰²è½¦ç‰ŒèŒƒå›´
        lower_yellow = np.array([20, 100, 100])
        upper_yellow = np.array([40, 255, 255])
        yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)

        # ç»¿è‰²è½¦ç‰ŒèŒƒå›´ï¼ˆæ–°èƒ½æºï¼‰
        lower_green = np.array([35, 100, 100])
        upper_green = np.array([85, 255, 255])
        green_mask = cv2.inRange(hsv, lower_green, upper_green)

        # å¤„ç†æ¯ç§é¢œè‰²
        for mask, color_name in [(blue_mask, 'blue'), (yellow_mask, 'yellow'), (green_mask, 'green')]:
            # å½¢æ€å­¦æ“ä½œ
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for contour in contours:
                area = cv2.contourArea(contour)
                if area < 500:
                    continue

                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h

                if aspect_ratio < 1.5 or aspect_ratio > 6.0:
                    continue

                plate_roi = image[y:y+h, x:x+w]
                if plate_roi.shape[0] < 15 or plate_roi.shape[1] < 50:
                    continue

                plates.append(plate_roi)

        return plates

    def detect_by_edges(self, processed_images: Dict[str, np.ndarray]) -> List[np.ndarray]:
        """åŸºäºè¾¹ç¼˜æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        if 'edges' not in processed_images:
            return plates

        edges = processed_images['edges']

        # å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((3, 3), np.uint8)
        edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)

        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 300:
                continue

            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h

            if aspect_ratio < 1.0 or aspect_ratio > 7.0:
                continue

            plate_roi = edges[y:y+h, x:x+w]
            if plate_roi.shape[0] < 12 or plate_roi.shape[1] < 40:
                continue

            plates.append(plate_roi)

        return plates

    def detect_by_morphology(self, processed_images: Dict[str, np.ndarray]) -> List[np.ndarray]:
        """åŸºäºå½¢æ€å­¦æ“ä½œæ£€æµ‹è½¦ç‰Œ"""
        plates = []

        # å°è¯•å¤šç§å½¢æ€å­¦ç»“æœ
        for method_name in ['morph', 'opening', 'tophat', 'gradient']:
            if method_name not in processed_images:
                continue

            image = processed_images[method_name]

            # è‡ªé€‚åº”é˜ˆå€¼
            adaptive = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)

            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(adaptive, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for contour in contours:
                area = cv2.contourArea(contour)
                if area < 250:
                    continue

                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = w / h

                if aspect_ratio < 1.2 or aspect_ratio > 6.5:
                    continue

                plate_roi = image[y:y+h, x:x+w]
                if plate_roi.shape[0] < 12 or plate_roi.shape[1] < 35:
                    continue

                plates.append(plate_roi)

        return plates

    def detect_by_sliding_window(self, image: np.ndarray) -> List[np.ndarray]:
        """åŸºäºæ»‘åŠ¨çª—å£æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        height, width = image.shape[:2]

        # å®šä¹‰æ»‘åŠ¨çª—å£å‚æ•°
        window_sizes = [
            (120, 40),   # æ ‡å‡†è½¦ç‰Œå°ºå¯¸
            (140, 50),   # ç¨å¤§å°ºå¯¸
            (160, 60),   # æ›´å¤§å°ºå¯¸
            (100, 35),   # ç¨å°å°ºå¯¸
        ]

        step_size = 20

        for window_width, window_height in window_sizes:
            for y in range(0, height - window_height, step_size):
                for x in range(0, width - window_width, step_size):
                    # æå–çª—å£åŒºåŸŸ
                    window = image[y:y+window_height, x:x+window_width]

                    # æ£€æŸ¥çª—å£åŒºåŸŸçš„è½¦ç‰Œç‰¹å¾
                    if self.is_license_plate_window(window):
                        plates.append(window)

        return plates

    def is_license_plate_window(self, window: np.ndarray) -> bool:
        """åˆ¤æ–­çª—å£æ˜¯å¦åŒ…å«è½¦ç‰Œç‰¹å¾"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(window.shape) == 3:
            gray = cv2.cvtColor(window, cv2.COLOR_BGR2GRAY)
        else:
            gray = window

        # è®¡ç®—è¾¹ç¼˜å¯†åº¦
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])

        # è®¡ç®—çº¹ç†å¤æ‚åº¦
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()

        # è½¦ç‰ŒåŒºåŸŸé€šå¸¸å…·æœ‰è¾ƒé«˜çš„è¾¹ç¼˜å¯†åº¦å’Œçº¹ç†å¤æ‚åº¦
        if edge_density > 0.1 and laplacian_var > 100:
            return True

        return False

    def extract_text_advanced(self, plate_image: np.ndarray) -> str:
        """é«˜çº§æ–‡å­—æå–"""
        if not self.tesseract_available:
            return ""

        try:
            # è½¬æ¢ä¸ºPILå›¾åƒ
            if len(plate_image.shape) == 3:
                plate_image = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)

            # å›¾åƒå¢å¼º
            pil_image = Image.fromarray(plate_image)

            # å¢å¼ºå¯¹æ¯”åº¦
            enhancer = ImageEnhance.Contrast(pil_image)
            pil_image = enhancer.enhance(2.5)

            # å¢åŠ æ¸…æ™°åº¦
            enhancer = ImageEnhance.Sharpness(pil_image)
            pil_image = enhancer.enhance(2.0)

            # è°ƒæ•´å¤§å°
            width, height = pil_image.size
            if width < 200:
                new_width = 300
                new_height = int(height * new_width / width)
                pil_image = pil_image.resize((new_width, new_height), Image.LANCZOS)

            # å¤šç§Tesseracté…ç½®
            configs = [
                r'--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†',
                r'--oem 3 --psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†',
                r'--oem 3 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†',
                r'--oem 3 --psm 11 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†',
                r'--oem 3 --psm 13 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†'
            ]

            results = []
            for config in configs:
                try:
                    text = pytesseract.image_to_string(pil_image, config=config)
                    text = text.strip().replace('\n', '').replace('\r', '').replace(' ', '')
                    if text and len(text) >= 6:  # è½¦ç‰Œè‡³å°‘6ä¸ªå­—ç¬¦
                        results.append(text)
                except:
                    continue

            # é€‰æ‹©æœ€é•¿çš„æœ‰æ•ˆç»“æœ
            valid_results = [r for r in results if self.validate_plate_format(r)]
            if valid_results:
                return max(valid_results, key=len)

            return ""

        except Exception as e:
            logger.error(f"æ–‡å­—æå–å¤±è´¥: {e}")
            return ""

    def validate_plate_format(self, text: str) -> bool:
        """éªŒè¯è½¦ç‰Œæ ¼å¼"""
        if not text or len(text) < 6 or len(text) > 9:
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆå­—ç¬¦
        valid_chars = PLATE_PROVINCES + PLATE_LETTERS + PLATE_NUMBERS
        return all(char in valid_chars for char in text)

    def determine_plate_type(self, plate_number: str) -> str:
        """æ ¹æ®è½¦ç‰Œå·ç¡®å®šè½¦ç‰Œç±»å‹"""
        if not plate_number:
            return "æœªçŸ¥"

        # æ–°èƒ½æºè½¦ç‰Œç‰¹å¾
        if len(plate_number) == 8 or plate_number[1] in ['D', 'F']:
            return "ç»¿ç‰Œ"

        # é»„ç‰Œç‰¹å¾
        if plate_number[1] in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M']:
            if plate_number.startswith('ä½¿'):
                return "ä½¿é¢†é¦†"
            return "é»„ç‰Œ"

        # é»˜è®¤è¿”å›è“ç‰Œ
        return "è“ç‰Œ"

    def calculate_confidence(self, text: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        if not text:
            return 0.0

        # åŸºç¡€ç½®ä¿¡åº¦
        base_confidence = 0.6

        # é•¿åº¦æ£€æŸ¥
        if 7 <= len(text) <= 8:
            base_confidence += 0.15

        # æ ¼å¼æ£€æŸ¥
        if self.validate_plate_format(text):
            base_confidence += 0.15

        # å­—ç¬¦è´¨é‡æ£€æŸ¥
        if text[0] in PLATE_PROVINCES:
            base_confidence += 0.05

        if text[1] in PLATE_LETTERS:
            base_confidence += 0.05

        return min(base_confidence, 0.99)

    def recognize_plate(self, image: Image.Image, filename: str) -> Dict[str, Any]:
        """ä¸»è¯†åˆ«å‡½æ•°"""
        start_time = time.time()

        try:
            # å…¨é¢çš„é¢„å¤„ç†
            processed_images, original_cv = self.comprehensive_preprocess(image)

            # ç»¼åˆæ£€æµ‹ç­–ç•¥
            all_plates = self.detect_license_plates_comprehensive(original_cv, processed_images)

            if not all_plates:
                return {
                    "plate_number": "æœªæ£€æµ‹åˆ°è½¦ç‰Œ",
                    "plate_type": "æœªçŸ¥",
                    "confidence": 0.0,
                    "processing_time": (time.time() - start_time) * 1000,
                    "success": False,
                    "method": "detection_failed"
                }

            # å¯¹æ¯ä¸ªå€™é€‰è½¦ç‰Œè¿›è¡ŒOCRè¯†åˆ«
            best_result = None
            best_confidence = 0

            for plate_image, method_name in all_plates:
                # æå–æ–‡å­—
                extracted_text = self.extract_text_advanced(plate_image)

                if extracted_text and self.validate_plate_format(extracted_text):
                    # ç¡®å®šè½¦ç‰Œç±»å‹
                    plate_type = self.determine_plate_type(extracted_text)

                    # è®¡ç®—ç½®ä¿¡åº¦
                    confidence = self.calculate_confidence(extracted_text)

                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_result = {
                            "plate_number": extracted_text,
                            "plate_type": plate_type,
                            "confidence": confidence,
                            "processing_time": (time.time() - start_time) * 1000,
                            "success": True,
                            "method": f"enhanced_ocr_{method_name}",
                            "note": f"å¢å¼ºOCRè¯†åˆ«ç»“æœ: {extracted_text}"
                        }

            if best_result:
                return best_result
            else:
                return {
                    "plate_number": "OCRè¯†åˆ«å¤±è´¥",
                    "plate_type": "æœªçŸ¥",
                    "confidence": 0.0,
                    "processing_time": (time.time() - start_time) * 1000,
                    "success": False,
                    "method": "ocr_failed"
                }

        except Exception as e:
            logger.error(f"OCRè¯†åˆ«å¤±è´¥: {e}")
            return {
                "plate_number": "å¤„ç†å¼‚å¸¸",
                "plate_type": "æœªçŸ¥",
                "confidence": 0.0,
                "processing_time": (time.time() - start_time) * 1000,
                "success": False,
                "method": "exception"
            }

# åˆå§‹åŒ–è¯†åˆ«å™¨
recognizer = EnhancedOCRRecognizer()

# æ•°æ®åº“åˆå§‹åŒ–
def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        conn = sqlite3.connect('enhanced_recognition_history.db')
        cursor = conn.cursor()

        # åˆ›å»ºå†å²è®°å½•è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS recognition_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                plate_number TEXT NOT NULL,
                plate_type TEXT NOT NULL,
                confidence REAL NOT NULL,
                processing_time REAL NOT NULL,
                image_path TEXT,
                method TEXT,
                note TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        conn.commit()
        conn.close()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

# æ•°æ®æ¨¡å‹
class RecognitionResult(BaseModel):
    plate_number: str
    plate_type: str
    confidence: float
    processing_time: float
    success: bool

# æ•°æ®åº“æ“ä½œå‡½æ•°
def save_to_history(result: Dict[str, Any], image_path: str = None):
    """ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ•°æ®åº“"""
    try:
        conn = sqlite3.connect('enhanced_recognition_history.db')
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO recognition_history
            (plate_number, plate_type, confidence, processing_time, image_path, method, note)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            result['plate_number'],
            result['plate_type'],
            result['confidence'],
            result['processing_time'],
            image_path,
            result.get('method', 'unknown'),
            result.get('note', '')
        ))

        conn.commit()
        conn.close()
    except Exception as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

# APIç«¯ç‚¹
@app.get("/", response_class=HTMLResponse)
async def read_root():
    """ä¸»é¡µ"""
    return """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>å¢å¼ºç‰ˆOCRè½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; display: flex; justify-content: center; align-items: center; }
            .container { background: white; padding: 2rem; border-radius: 20px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); max-width: 800px; width: 90%; }
            h1 { text-align: center; color: #333; margin-bottom: 2rem; font-size: 2.5rem; }
            .upload-section { margin-bottom: 2rem; text-align: center; }
            .file-input { display: none; }
            .file-label { display: inline-block; padding: 12px 24px; background: #4CAF50; color: white; border-radius: 8px; cursor: pointer; transition: background 0.3s; }
            .file-label:hover { background: #45a049; }
            .result { margin-top: 2rem; padding: 1rem; border-radius: 8px; background: #f5f5f5; display: none; }
            .result.show { display: block; }
            .success { background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
            .error { background: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
            .status { text-align: center; margin-bottom: 1rem; }
            .status-indicator { display: inline-block; width: 12px; height: 12px; border-radius: 50%; margin-right: 8px; }
            .online { background: #4CAF50; }
            .offline { background: #f44336; }
            .info-box { background: #e3f2fd; border: 1px solid #bbdefb; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; }
            .info-box h3 { color: #1976d2; margin-bottom: 0.5rem; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš— å¢å¼ºç‰ˆOCRè½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</h1>

            <div class="status">
                <span class="status-indicator online"></span>
                <span id="statusText">æœåŠ¡å™¨çŠ¶æ€: åœ¨çº¿</span>
            </div>

            <div class="info-box">
                <h3>ç³»ç»Ÿç‰¹ç‚¹</h3>
                <p>â€¢ å¤šé‡æ£€æµ‹ç­–ç•¥ï¼ˆè½®å»“ã€é¢œè‰²ã€è¾¹ç¼˜ã€å½¢æ€å­¦ã€æ»‘åŠ¨çª—å£ï¼‰</p>
                <p>â€¢ é«˜çº§å›¾åƒé¢„å¤„ç†ç®—æ³•</p>
                <p>â€¢ æ™ºèƒ½fallbackæœºåˆ¶</p>
                <p>â€¢ å®Œå…¨åŸºäºçœŸå®OCRæŠ€æœ¯</p>
            </div>

            <div class="upload-section">
                <input type="file" id="fileInput" class="file-input" accept="image/*" onchange="uploadFile(this)">
                <label for="fileInput" class="file-label">é€‰æ‹©å›¾ç‰‡è¿›è¡Œè¯†åˆ«</label>
            </div>

            <div id="result" class="result"></div>
        </div>

        <script>
            function uploadFile(input) {
                const file = input.files[0];
                if (!file) return;

                const formData = new FormData();
                formData.append('file', file);

                document.getElementById('result').innerHTML = '<div class="loading">æ­£åœ¨è¯†åˆ«ä¸­...</div>';
                document.getElementById('result').classList.add('show');

                fetch('/recognize', {
                    method: 'POST',
                    body: formData
                })
                .then(response => response.json())
                .then(data => {
                    displayResult(data);
                })
                .catch(error => {
                    document.getElementById('result').innerHTML = '<div class="error">è¯†åˆ«å¤±è´¥: ' + error.message + '</div>';
                });
            }

            function displayResult(data) {
                const resultDiv = document.getElementById('result');
                if (data.success) {
                    resultDiv.innerHTML = `
                        <div class="success">
                            <h3>è¯†åˆ«æˆåŠŸï¼</h3>
                            <p><strong>è½¦ç‰Œå·ç :</strong> ${data.plate_number}</p>
                            <p><strong>è½¦ç‰Œç±»å‹:</strong> ${data.plate_type}</p>
                            <p><strong>ç½®ä¿¡åº¦:</strong> ${(data.confidence * 100).toFixed(1)}%</p>
                            <p><strong>å¤„ç†æ—¶é—´:</strong> ${data.processing_time.toFixed(2)}ms</p>
                            <p><strong>è¯†åˆ«æ–¹æ³•:</strong> ${data.method}</p>
                            <p><strong>å¤‡æ³¨:</strong> ${data.note}</p>
                        </div>
                    `;
                } else {
                    resultDiv.innerHTML = '<div class="error">è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•</div>';
                }
            }

            // æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
            function checkServerStatus() {
                fetch('/health')
                    .then(response => response.json())
                    .then(data => {
                        document.getElementById('statusText').textContent = 'æœåŠ¡å™¨çŠ¶æ€: åœ¨çº¿';
                        document.querySelector('.status-indicator').className = 'status-indicator online';
                    })
                    .catch(error => {
                        document.getElementById('statusText').textContent = 'æœåŠ¡å™¨çŠ¶æ€: ç¦»çº¿';
                        document.querySelector('.status-indicator').className = 'status-indicator offline';
                    });
            }

            // å®šæœŸæ£€æŸ¥çŠ¶æ€
            checkServerStatus();
            setInterval(checkServerStatus, 30000);
        </script>
    </body>
    </html>
    """

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_type": "EnhancedOCRRecognizer",
        "device": "cpu",
        "tesseract_available": TESSERACT_AVAILABLE,
        "recognition_method": "enhanced_ocr",
        "detection_strategies": ["contour", "color", "edge", "morphology", "sliding_window"],
        "preset_mappings": "none"
    }

@app.post("/recognize", response_model=RecognitionResult)
async def recognize_plate(file: UploadFile = File(...)):
    """å•ä¸ªè½¦ç‰Œè¯†åˆ«"""
    try:
        start_time = time.time()

        # è¯»å–å›¾åƒ
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        # è¿›è¡ŒOCRè¯†åˆ«
        result = recognizer.recognize_plate(image, file.filename)

        # ä¿å­˜åˆ°å†å²è®°å½•
        save_to_history(result)

        return result

    except Exception as e:
        logger.error(f"è¯†åˆ«å¤±è´¥: {e}")
        return {
            "plate_number": "å¤„ç†å¼‚å¸¸",
            "plate_type": "æœªçŸ¥",
            "confidence": 0.0,
            "processing_time": 20.0,
            "success": False
        }

@app.get("/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        conn = sqlite3.connect('enhanced_recognition_history.db')
        cursor = conn.cursor()

        # è·å–æ€»è¯†åˆ«æ¬¡æ•°
        cursor.execute("SELECT COUNT(*) FROM recognition_history")
        total_count = cursor.fetchone()[0]

        # è·å–æˆåŠŸè¯†åˆ«æ¬¡æ•°
        cursor.execute("SELECT COUNT(*) FROM recognition_history WHERE confidence >= 0.5")
        successful_count = cursor.fetchone()[0]

        # è·å–å¹³å‡ç½®ä¿¡åº¦
        cursor.execute("SELECT AVG(confidence) FROM recognition_history")
        avg_confidence = cursor.fetchone()[0] or 0

        conn.close()

        return {
            "total_recognitions": total_count,
            "successful_recognitions": successful_count,
            "success_rate": (successful_count / total_count * 100) if total_count > 0 else 0,
            "average_confidence": avg_confidence
        }

    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return {
            "total_recognitions": 0,
            "successful_recognitions": 0,
            "success_rate": 0.0,
            "average_confidence": 0.0
        }

@app.get("/history")
async def get_history():
    """è·å–å†å²è®°å½•"""
    try:
        conn = sqlite3.connect('enhanced_recognition_history.db')
        cursor = conn.cursor()

        cursor.execute('''
            SELECT plate_number, plate_type, confidence, processing_time, method, timestamp
            FROM recognition_history
            ORDER BY timestamp DESC
            LIMIT 100
        ''')

        history = []
        for row in cursor.fetchall():
            history.append({
                "plate_number": row[0],
                "plate_type": row[1],
                "confidence": row[2],
                "processing_time": row[3],
                "method": row[4],
                "timestamp": row[5]
            })

        conn.close()

        return {"history": history}

    except Exception as e:
        logger.error(f"è·å–å†å²è®°å½•å¤±è´¥: {e}")
        return {"history": []}

if __name__ == "__main__":
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()

    print("å¢å¼ºç‰ˆOCRè½¦ç‰Œè¯†åˆ«ç³»ç»Ÿå¯åŠ¨")
    print("ç‰¹ç‚¹:")
    print("- å¤šé‡æ£€æµ‹ç­–ç•¥ï¼ˆè½®å»“ã€é¢œè‰²ã€è¾¹ç¼˜ã€å½¢æ€å­¦ã€æ»‘åŠ¨çª—å£ï¼‰")
    print("- é«˜çº§å›¾åƒé¢„å¤„ç†ç®—æ³•")
    print("- æ™ºèƒ½fallbackæœºåˆ¶")
    print("- å®Œå…¨åŸºäºçœŸå®OCRæŠ€æœ¯")
    print("- ç¡®ä¿è¯†åˆ«ç»“æœä¸å›¾ç‰‡å†…å®¹å®Œå…¨å¯¹åº”")
    print("=" * 50)

    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(app, host="0.0.0.0", port=8020, reload=False)