#!/usr/bin/env python3
"""
è½¦ç‰Œè¯†åˆ«API - å®Œç¾åŒ¹é…è®­ç»ƒæ¨¡å‹ç»“æ„
åŸºäºåŸå§‹è®­ç»ƒæ¶æ„çš„ç²¾ç¡®å®ç°
"""

import io
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import numpy as np
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
import uvicorn
import time
from typing import List, Dict, Any
import os

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ",
    description="åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­å›½è½¦ç‰Œè¯†åˆ«è§£å†³æ–¹æ¡ˆ",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å®šä¹‰å“åº”æ¨¡å‹
class RecognitionResult(BaseModel):
    plate_number: str
    plate_type: str
    confidence: float
    processing_time: float

# å®Œå…¨åŒ¹é…åŸå§‹æ¨¡å‹ç»“æ„çš„è½¦ç‰Œè¯†åˆ«æ¨¡å‹
class PerfectLicensePlateRecognizer(nn.Module):
    def __init__(self):
        super(PerfectLicensePlateRecognizer, self).__init__()

        # ä½ç½®ç¼–ç 
        self.positional_encoding = nn.Parameter(torch.randn(1, 8, 128))

        # ResNetéª¨å¹²ç½‘ç»œ - å®Œå…¨åŒ¹é…åŸå§‹ç»“æ„
        self.backbone = nn.ModuleDict({
            '0': nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
            '1': nn.BatchNorm2d(64),

            # ResNetå—
            '4': nn.ModuleDict({
                '0': nn.ModuleDict({
                    'conv1': nn.Conv2d(64, 64, kernel_size=3, padding=1),
                    'bn1': nn.BatchNorm2d(64),
                    'conv2': nn.Conv2d(64, 64, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(64),
                }),
                '1': nn.ModuleDict({
                    'conv1': nn.Conv2d(64, 64, kernel_size=3, padding=1),
                    'bn1': nn.BatchNorm2d(64),
                    'conv2': nn.Conv2d(64, 64, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(64),
                })
            }),

            '5': nn.ModuleDict({
                '0': nn.ModuleDict({
                    'conv1': nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
                    'bn1': nn.BatchNorm2d(128),
                    'conv2': nn.Conv2d(128, 128, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(128),
                    'downsample': nn.ModuleDict({
                        '0': nn.Conv2d(64, 128, kernel_size=1, stride=2),
                        '1': nn.BatchNorm2d(128),
                    })
                }),
                '1': nn.ModuleDict({
                    'conv1': nn.Conv2d(128, 128, kernel_size=3, padding=1),
                    'bn1': nn.BatchNorm2d(128),
                    'conv2': nn.Conv2d(128, 128, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(128),
                })
            }),

            '6': nn.ModuleDict({
                '0': nn.ModuleDict({
                    'conv1': nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
                    'bn1': nn.BatchNorm2d(256),
                    'conv2': nn.Conv2d(256, 256, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(256),
                    'downsample': nn.ModuleDict({
                        '0': nn.Conv2d(128, 256, kernel_size=1, stride=2),
                        '1': nn.BatchNorm2d(256),
                    })
                }),
                '1': nn.ModuleDict({
                    'conv1': nn.Conv2d(256, 256, kernel_size=3, padding=1),
                    'bn1': nn.BatchNorm2d(256),
                    'conv2': nn.Conv2d(256, 256, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(256),
                })
            }),

            '7': nn.ModuleDict({
                '0': nn.ModuleDict({
                    'conv1': nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),
                    'bn1': nn.BatchNorm2d(512),
                    'conv2': nn.Conv2d(512, 512, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(512),
                    'downsample': nn.ModuleDict({
                        '0': nn.Conv2d(256, 512, kernel_size=1, stride=2),
                        '1': nn.BatchNorm2d(512),
                    })
                }),
                '1': nn.ModuleDict({
                    'conv1': nn.Conv2d(512, 512, kernel_size=3, padding=1),
                    'bn1': nn.BatchNorm2d(512),
                    'conv2': nn.Conv2d(512, 512, kernel_size=3, padding=1),
                    'bn2': nn.BatchNorm2d(512),
                })
            })
        })

        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.ModuleDict({
            'fc': nn.Sequential(
                nn.Linear(512, 64),
                nn.ReLU(),
                nn.Linear(64, 512),
                nn.Sigmoid()
            )
        })

        # ç‰¹å¾å¢å¼º
        self.feature_enhancement = nn.Sequential(
            nn.Conv2d(512, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )

        # å­—ç¬¦åˆ†ç±»å™¨
        self.char_classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 72)  # 72ä¸ªå­—ç¬¦
        )

        # è½¦ç‰Œç±»å‹åˆ†ç±»å™¨
        self.type_classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 9)   # 9ç§ç±»å‹
        )

        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

    def forward(self, x):
        # åˆå§‹å·ç§¯
        x = self.backbone['0'](x)
        x = self.backbone['1'](x)
        x = self.relu(x)
        x = self.maxpool(x)

        # ResNetå—
        x = self._resnet_block(x, self.backbone['4'])
        x = self._resnet_block(x, self.backbone['5'])
        x = self._resnet_block(x, self.backbone['6'])
        x = self._resnet_block(x, self.backbone['7'])

        # æ³¨æ„åŠ›æœºåˆ¶
        batch_size, channels, height, width = x.size()
        gap = F.adaptive_avg_pool2d(x, 1).view(batch_size, channels)
        attention = self.attention['fc'](gap).view(batch_size, channels, 1, 1)
        x = x * attention

        # ç‰¹å¾å¢å¼º
        x = self.feature_enhancement(x)

        # å…¨å±€å¹³å‡æ± åŒ–
        global_feat = F.adaptive_avg_pool2d(x, (1, 1)).view(batch_size, -1)

        # è½¦ç‰Œç±»å‹åˆ†ç±»
        type_logits = self.type_classifier(global_feat)

        # å­—ç¬¦åºåˆ—é¢„æµ‹
        seq_features = x.mean(dim=2)  # å¹³å‡æ± åŒ–é«˜åº¦ç»´åº¦
        seq_features = seq_features.permute(0, 2, 1)  # [batch, width, channels]

        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_encoding = self.positional_encoding[:, :seq_features.size(1), :]
        seq_features = seq_features + pos_encoding

        # å­—ç¬¦åˆ†ç±»
        char_logits = self.char_classifier(seq_features)

        return char_logits, type_logits

    def _resnet_block(self, x, block_dict):
        """å¤„ç†ResNetå—"""
        # ç¬¬ä¸€ä¸ªå­å—
        residual = x
        out = self.relu(block_dict['0']['bn1'](block_dict['0']['conv1'](x)))
        out = block_dict['0']['bn2'](block_dict['0']['conv2'](out))

        # ä¸‹é‡‡æ ·
        if 'downsample' in block_dict['0']:
            residual = block_dict['0']['downsample']['1'](
                block_dict['0']['downsample']['0'](x)
            )

        out += residual
        out = self.relu(out)

        # ç¬¬äºŒä¸ªå­å—
        residual = out
        out = self.relu(block_dict['1']['bn1'](block_dict['1']['conv1'](out)))
        out = block_dict['1']['bn2'](block_dict['1']['conv2'](out))
        out += residual
        out = self.relu(out)

        return out

# è½¦ç‰Œå­—ç¬¦æ˜ å°„ - ç²¾ç¡®åŒ¹é…72ä¸ªå­—ç¬¦
PLATE_CHARS = [
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
    'äº¬', 'æ´¥', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 'æ²ª', 'è‹', 'æµ™', 'çš–', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 'æ¡‚', 'ç¼',
    'æ¸', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', 'é’', 'å®', 'æ–°', 'æ¸¯', 'æ¾³', 'å°'
]

PLATE_TYPES = [
    'è“ç‰Œ', 'é»„ç‰Œ', 'ç»¿ç‰Œ', 'ç™½ç‰Œ', 'é»‘ç‰Œ', 'è­¦è½¦', 'å†›è½¦', 'ä½¿é¦†', 'å…¶ä»–'
]

# å…¨å±€å˜é‡
model = None
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def load_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    global model

    try:
        print("æ­£åœ¨åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = PerfectLicensePlateRecognizer()

        # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
        checkpoint = torch.load('best_fast_high_accuracy_model.pth', map_location='cpu')

        # åŠ è½½æ¨¡å‹æƒé‡
        model.load_state_dict(checkpoint, strict=True)

        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()

        # ç§»åŠ¨åˆ°è®¾å¤‡
        model = model.to(device)

        print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {device}")
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        return True

    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def preprocess_image(image):
    """é¢„å¤„ç†å›¾åƒ"""
    # è½¬æ¢ä¸ºRGB
    if image.mode != 'RGB':
        image = image.convert('RGB')

    # è°ƒæ•´å¤§å°
    image = image.resize((384, 96), Image.Resampling.LANCZOS)

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    img_array = np.array(image, dtype=np.float32) / 255.0

    # æ ‡å‡†åŒ–
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img_array = (img_array - mean) / std

    # è½¬æ¢ä¸ºtensorå¹¶ç¡®ä¿æ•°æ®ç±»å‹ä¸€è‡´
    img_tensor = torch.from_numpy(img_array).float()
    img_tensor = img_tensor.transpose(0, 2).transpose(1, 2)
    img_tensor = img_tensor.unsqueeze(0)

    return img_tensor.to(device)

def decode_prediction(char_logits, type_logits):
    """è§£ç é¢„æµ‹ç»“æœ"""
    # å­—ç¬¦é¢„æµ‹
    char_probs = F.softmax(char_logits, dim=-1)
    char_indices = torch.argmax(char_probs, dim=-1)

    # è½¬æ¢ä¸ºå­—ç¬¦
    plate_chars = []
    for idx in char_indices[0]:
        if idx < len(PLATE_CHARS):
            plate_chars.append(PLATE_CHARS[idx])
        else:
            plate_chars.append('?')

    # è¿‡æ»¤è¿ç»­é‡å¤å­—ç¬¦
    filtered_chars = []
    for i, char in enumerate(plate_chars):
        if i == 0 or char != plate_chars[i-1]:
            filtered_chars.append(char)

    # é™åˆ¶é•¿åº¦
    plate_number = ''.join(filtered_chars[:8])

    # è½¦ç‰Œç±»å‹é¢„æµ‹
    type_probs = F.softmax(type_logits, dim=-1)
    type_idx = torch.argmax(type_probs, dim=-1)[0].item()
    plate_type = PLATE_TYPES[type_idx]

    # è®¡ç®—ç½®ä¿¡åº¦
    confidence = torch.max(type_probs).item()

    return plate_number, plate_type, confidence

def recognize_plate(image):
    """è¯†åˆ«è½¦ç‰Œ"""
    start_time = time.time()

    try:
        # é¢„å¤„ç†
        img_tensor = preprocess_image(image)

        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            char_logits, type_logits = model(img_tensor)

        # è§£ç ç»“æœ
        plate_number, plate_type, confidence = decode_prediction(char_logits, type_logits)

        # å¤„ç†æ—¶é—´
        processing_time = (time.time() - start_time) * 1000

        return {
            "plate_number": plate_number,
            "plate_type": plate_type,
            "confidence": confidence,
            "processing_time": processing_time
        }

    except Exception as e:
        print(f"è¯†åˆ«å¤±è´¥: {e}")
        return {
            "plate_number": "è¯†åˆ«å¤±è´¥",
            "plate_type": "æœªçŸ¥",
            "confidence": 0.0,
            "processing_time": 0.0
        }

# APIç«¯ç‚¹
@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
            .container {{ max-width: 800px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); padding: 40px; text-align: center; }}
            h1 {{ color: #333; margin-bottom: 30px; font-size: 2.5em; }}
            .btn {{ display: inline-block; background: linear-gradient(45deg, #667eea, #764ba2); color: white; text-decoration: none; padding: 15px 30px; border-radius: 25px; margin: 10px; font-size: 1.1em; transition: all 0.3s ease; }}
            .btn:hover {{ transform: translateY(-2px); box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4); }}
            .info {{ background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0; }}
            .status {{ padding: 10px; border-radius: 5px; margin: 10px 0; }}
            .status.success {{ background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš— è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</h1>
            <div class="info">
                <p>åŸºäºæ·±åº¦å­¦ä¹ çš„æ™ºèƒ½è½¦ç‰Œè¯†åˆ«è§£å†³æ–¹æ¡ˆ</p>
                <p>ä½¿ç”¨åŸå§‹è®­ç»ƒå¥½çš„é«˜ç²¾åº¦æ¨¡å‹</p>
                <div class="status success">
                    ç³»ç»ŸçŠ¶æ€: è¿è¡Œæ­£å¸¸ | æ¨¡å‹: å·²åŠ è½½ | è®¾å¤‡: {device}
                </div>
            </div>
            <div>
                <a href="/web" class="btn">è¿›å…¥Webç•Œé¢</a>
                <a href="/docs" class="btn">APIæ–‡æ¡£</a>
                <a href="/test" class="btn">åŠŸèƒ½æµ‹è¯•</a>
            </div>
        </div>
    </body>
    </html>
    """

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "device": str(device),
        "model_type": "åŸå§‹è®­ç»ƒé«˜ç²¾åº¦æ¨¡å‹"
    }

@app.get("/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    return {
        "device": str(device),
        "model_loaded": model is not None,
        "supported_formats": ["jpg", "jpeg", "png", "bmp", "tiff"],
        "max_file_size": "10MB",
        "model_type": "åŸå§‹è®­ç»ƒResNetæ¨¡å‹",
        "num_chars": len(PLATE_CHARS),
        "num_plate_types": len(PLATE_TYPES)
    }

@app.post("/recognize", response_model=RecognitionResult)
async def recognize_plate_api(file: UploadFile = File(...)):
    """å•å¼ å›¾ç‰‡è¯†åˆ«"""
    try:
        # è¯»å–å›¾ç‰‡
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        # è¯†åˆ«è½¦ç‰Œ
        result = recognize_plate(image)

        return RecognitionResult(
            plate_number=result["plate_number"],
            plate_type=result["plate_type"],
            confidence=result["confidence"],
            processing_time=result["processing_time"]
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/recognize_batch")
async def recognize_batch_api(files: List[UploadFile] = File(...)):
    """æ‰¹é‡è¯†åˆ«"""
    results = []

    for file in files:
        try:
            contents = await file.read()
            image = Image.open(io.BytesIO(contents))

            result = recognize_plate(image)
            results.append({
                "filename": file.filename,
                "plate_number": result["plate_number"],
                "plate_type": result["plate_type"],
                "confidence": result["confidence"],
                "processing_time": result["processing_time"]
            })

        except Exception as e:
            results.append({
                "filename": file.filename,
                "error": str(e)
            })

    return {"results": results}

@app.get("/web", response_class=HTMLResponse)
async def web_interface():
    """Webç•Œé¢"""
    return """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { font-family: 'Microsoft YaHei', Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; }
            .container { max-width: 1200px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); overflow: hidden; }
            .header { background: linear-gradient(45deg, #667eea, #764ba2); color: white; padding: 30px; text-align: center; }
            .header h1 { font-size: 2.5em; margin-bottom: 10px; }
            .main-content { padding: 40px; }
            .upload-section { border: 3px dashed #ddd; border-radius: 10px; padding: 40px; text-align: center; margin-bottom: 30px; }
            .upload-btn { background: linear-gradient(45deg, #667eea, #764ba2); color: white; border: none; padding: 15px 30px; border-radius: 25px; font-size: 1.1em; cursor: pointer; margin: 10px; }
            .file-input { display: none; }
            .preview-section { display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 30px; }
            .image-preview, .result-preview { background: #f8f9fa; border-radius: 10px; padding: 20px; text-align: center; }
            .plate-number { font-size: 2em; font-weight: bold; color: #667eea; text-align: center; padding: 15px; background: linear-gradient(45deg, #f0f4ff, #e8f0ff); border-radius: 10px; margin: 15px 0; }
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸš— è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</h1>
                <p>ä½¿ç”¨åŸå§‹è®­ç»ƒæ¨¡å‹çš„é«˜ç²¾åº¦è¯†åˆ«</p>
            </div>
            <div class="main-content">
                <div class="upload-section">
                    <h2>ğŸ“¤ ä¸Šä¼ å›¾ç‰‡è¿›è¡Œè¯†åˆ«</h2>
                    <button class="upload-btn" onclick="document.getElementById('fileInput').click()">é€‰æ‹©å›¾ç‰‡</button>
                    <input type="file" id="fileInput" class="file-input" accept="image/*" onchange="handleFile(this.files[0])">
                </div>
                <div class="preview-section" id="previewSection" style="display: none;">
                    <div class="image-preview">
                        <h3>ğŸ“· åŸå§‹å›¾ç‰‡</h3>
                        <img id="previewImage" alt="é¢„è§ˆå›¾ç‰‡" style="max-width: 100%; max-height: 300px;">
                    </div>
                    <div class="result-preview">
                        <h3>ğŸ¯ è¯†åˆ«ç»“æœ</h3>
                        <div class="plate-number" id="plateNumber">ç­‰å¾…è¯†åˆ«...</div>
                        <div><strong>è½¦ç‰Œç±»å‹:</strong> <span id="plateType">-</span></div>
                        <div><strong>ç½®ä¿¡åº¦:</strong> <span id="confidence">-</span></div>
                        <div><strong>å¤„ç†æ—¶é—´:</strong> <span id="processingTime">-</span></div>
                    </div>
                </div>
            </div>
        </div>

        <script>
        async function handleFile(file) {
            if (!file) return;

            const previewImage = document.getElementById('previewImage');
            const previewSection = document.getElementById('previewSection');

            // æ˜¾ç¤ºé¢„è§ˆ
            previewImage.src = URL.createObjectURL(file);
            previewSection.style.display = 'grid';

            // ä¸Šä¼ è¯†åˆ«
            const formData = new FormData();
            formData.append('file', file);

            try {
                const response = await fetch('/recognize', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (response.ok) {
                    document.getElementById('plateNumber').textContent = result.plate_number;
                    document.getElementById('plateType').textContent = result.plate_type;
                    document.getElementById('confidence').textContent = Math.round(result.confidence * 100) + '%';
                    document.getElementById('processingTime').textContent = result.processing_time.toFixed(2) + 'ms';
                } else {
                    alert('è¯†åˆ«å¤±è´¥: ' + result.detail);
                }
            } catch (error) {
                alert('ç½‘ç»œé”™è¯¯: ' + error.message);
            }
        }
        </script>
    </body>
    </html>
    """

# å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶"""
    success = load_model()
    if not success:
        print("è­¦å‘Š: æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç³»ç»Ÿå°†ä½¿ç”¨éšæœºæƒé‡")

    print("è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿå¯åŠ¨å®Œæˆ")
    print("ç³»ç»Ÿè®¿é—®åœ°å€:")
    print("  - ä¸»é¡µ: http://localhost:8001")
    print("  - Webç•Œé¢: http://localhost:8001/web")
    print("  - APIæ–‡æ¡£: http://localhost:8001/docs")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)