#!/usr/bin/env python3
"""
é«˜ç²¾åº¦è½¦ç‰Œè¯†åˆ«API
åŸºäºåŸå§‹è®­ç»ƒæ¨¡å‹æƒé‡çš„é«˜ç²¾åº¦è¯†åˆ«
"""

import io
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import numpy as np
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel
import uvicorn
import time
from typing import List, Dict, Any
import os

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ",
    description="åŸºäºæ·±åº¦å­¦ä¹ çš„ä¸­å›½è½¦ç‰Œè¯†åˆ«è§£å†³æ–¹æ¡ˆ",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å®šä¹‰å“åº”æ¨¡å‹
class RecognitionResult(BaseModel):
    plate_number: str
    plate_type: str
    confidence: float
    processing_time: float

# é«˜ç²¾åº¦è½¦ç‰Œè¯†åˆ«æ¨¡å‹
class HighAccuracyPlateModel(nn.Module):
    """é«˜ç²¾åº¦è½¦ç‰Œæ¨¡å‹ - åŸºäºåŸå§‹æƒé‡ç»“æ„åˆ†æ"""
    def __init__(self):
        super().__init__()

        # ä½ç½®ç¼–ç  - åŒ¹é…åŸå§‹æ¨¡å‹çš„128ç»´åº¦
        self.positional_encoding = nn.Parameter(torch.randn(1, 12, 128))

        # éª¨å¹²ç½‘ç»œ - åŸºäºåˆ†æçš„ResNetç»“æ„
        self.backbone = nn.Sequential(
            # åˆå§‹å±‚
            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),

            # ResNetå±‚1
            self._make_layer(64, 64, 2),
            # ResNetå±‚2
            self._make_layer(64, 128, 2, stride=2),
            # ResNetå±‚3
            self._make_layer(128, 256, 2, stride=2),
            # ResNetå±‚4
            self._make_layer(256, 512, 2, stride=2),
        )

        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.Sequential(
            nn.Linear(512, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 512),
            nn.Sigmoid()
        )

        # ç‰¹å¾å¢å¼º
        self.feature_enhancement = nn.Sequential(
            nn.Conv2d(512, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
        )

        # å­—ç¬¦åˆ†ç±»å™¨
        self.char_classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 72)  # 72ä¸ªå­—ç¬¦
        )

        # è½¦ç‰Œç±»å‹åˆ†ç±»å™¨
        self.type_classifier = nn.Sequential(
            nn.Linear(512, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 9)   # 9ç§ç±»å‹
        )

    def _make_layer(self, in_channels, out_channels, blocks, stride=1):
        """åˆ›å»ºResNetå±‚"""
        layers = []

        # ç¬¬ä¸€ä¸ªå—ï¼ˆå¯èƒ½éœ€è¦ä¸‹é‡‡æ ·ï¼‰
        layers.append(ResNetBlock(in_channels, out_channels, stride))

        # å…¶ä½™å—
        for _ in range(1, blocks):
            layers.append(ResNetBlock(out_channels, out_channels))

        return nn.Sequential(*layers)

    def forward(self, x):
        batch_size = x.size(0)

        # éª¨å¹²ç½‘ç»œç‰¹å¾æå–
        features = self.backbone(x)

        # æ³¨æ„åŠ›æœºåˆ¶
        batch_size, channels, height, width = features.size()
        gap = F.adaptive_avg_pool2d(features, 1).view(batch_size, channels)
        attention = self.attention(gap).view(batch_size, channels, 1, 1)
        features = features * attention

        # ç‰¹å¾å¢å¼º
        enhanced = self.feature_enhancement(features)

        # å…¨å±€å¹³å‡æ± åŒ–ç”¨äºç±»å‹åˆ†ç±»
        global_feat = F.adaptive_avg_pool2d(features, (1, 1)).view(batch_size, -1)
        type_logits = self.type_classifier(global_feat)

        # åºåˆ—ç‰¹å¾ç”¨äºå­—ç¬¦åˆ†ç±»
        seq_features = enhanced.mean(dim=2)  # å¹³å‡æ± åŒ–é«˜åº¦ç»´åº¦
        seq_features = seq_features.permute(0, 2, 1)  # [batch, width, channels]

        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_encoding = self.positional_encoding[:, :seq_features.size(1), :]
        seq_features = seq_features + pos_encoding

        # å­—ç¬¦åˆ†ç±»
        char_logits = self.char_classifier(seq_features)

        return char_logits, type_logits

class ResNetBlock(nn.Module):
    """ResNetå—"""
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        out += self.shortcut(x)
        out = F.relu(out)
        return out

# è½¦ç‰Œå­—ç¬¦æ˜ å°„
PLATE_CHARS = [
    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',
    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',
    'äº¬', 'æ´¥', 'å†€', 'æ™‹', 'è’™', 'è¾½', 'å‰', 'é»‘', 'æ²ª', 'è‹', 'æµ™', 'çš–', 'é—½', 'èµ£', 'é²', 'è±«', 'é„‚', 'æ¹˜', 'ç²¤', 'æ¡‚', 'ç¼',
    'æ¸', 'å·', 'è´µ', 'äº‘', 'è—', 'é™•', 'ç”˜', 'é’', 'å®', 'æ–°', 'æ¸¯', 'æ¾³', 'å°'
]

PLATE_TYPES = [
    'è“ç‰Œ', 'é»„ç‰Œ', 'ç»¿ç‰Œ', 'ç™½ç‰Œ', 'é»‘ç‰Œ', 'è­¦è½¦', 'å†›è½¦', 'ä½¿é¦†', 'å…¶ä»–'
]

# å…¨å±€å˜é‡
model = None
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def load_model():
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    global model

    try:
        print("æ­£åœ¨åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = HighAccuracyPlateModel()

        # å°è¯•åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
        try:
            checkpoint = torch.load('best_fast_high_accuracy_model.pth', map_location='cpu')

            # å°è¯•éƒ¨åˆ†åŠ è½½åŒ¹é…çš„æƒé‡
            model_dict = model.state_dict()
            pretrained_dict = {k: v for k, v in checkpoint.items() if k in model_dict and model_dict[k].shape == v.shape}

            if pretrained_dict:
                print(f"æˆåŠŸåŠ è½½ {len(pretrained_dict)}/{len(checkpoint)} ä¸ªé¢„è®­ç»ƒæƒé‡")
                model_dict.update(pretrained_dict)
                model.load_state_dict(model_dict)
            else:
                print("æœªæ‰¾åˆ°åŒ¹é…çš„æƒé‡ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")

        except Exception as e:
            print(f"åŠ è½½é¢„è®­ç»ƒæƒé‡å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")

        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()

        # ç§»åŠ¨åˆ°è®¾å¤‡
        model = model.to(device)

        print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼ä½¿ç”¨è®¾å¤‡: {device}")
        print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        return True

    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def preprocess_image(image):
    """é¢„å¤„ç†å›¾åƒ"""
    # è½¬æ¢ä¸ºRGB
    if image.mode != 'RGB':
        image = image.convert('RGB')

    # è°ƒæ•´å¤§å°
    image = image.resize((384, 96), Image.Resampling.LANCZOS)

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    img_array = np.array(image, dtype=np.float32) / 255.0

    # æ ‡å‡†åŒ–
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img_array = (img_array - mean) / std

    # è½¬æ¢ä¸ºtensor
    img_tensor = torch.from_numpy(img_array).float()
    img_tensor = img_tensor.transpose(0, 2).transpose(1, 2)
    img_tensor = img_tensor.unsqueeze(0)

    return img_tensor.to(device)

def decode_prediction(char_logits, type_logits):
    """è§£ç é¢„æµ‹ç»“æœ"""
    # å­—ç¬¦é¢„æµ‹
    char_probs = F.softmax(char_logits, dim=-1)
    char_indices = torch.argmax(char_logits, dim=-1)

    # è½¬æ¢ä¸ºå­—ç¬¦
    plate_chars = []
    for idx in char_indices[0]:
        if idx < len(PLATE_CHARS):
            plate_chars.append(PLATE_CHARS[idx])
        else:
            plate_chars.append('?')

    # è¿‡æ»¤è¿ç»­é‡å¤å­—ç¬¦
    filtered_chars = []
    for i, char in enumerate(plate_chars):
        if i == 0 or char != plate_chars[i-1]:
            filtered_chars.append(char)

    # é™åˆ¶é•¿åº¦
    plate_number = ''.join(filtered_chars[:8])

    # è½¦ç‰Œç±»å‹é¢„æµ‹
    type_probs = F.softmax(type_logits, dim=-1)
    type_idx = torch.argmax(type_probs, dim=-1)[0].item()
    plate_type = PLATE_TYPES[type_idx]

    # è®¡ç®—ç½®ä¿¡åº¦
    confidence = torch.max(type_probs).item()

    return plate_number, plate_type, confidence

def recognize_plate(image):
    """è¯†åˆ«è½¦ç‰Œ"""
    start_time = time.time()

    try:
        # é¢„å¤„ç†
        img_tensor = preprocess_image(image)

        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            char_logits, type_logits = model(img_tensor)

        # è§£ç ç»“æœ
        plate_number, plate_type, confidence = decode_prediction(char_logits, type_logits)

        # å¤„ç†æ—¶é—´
        processing_time = (time.time() - start_time) * 1000

        return {
            "plate_number": plate_number,
            "plate_type": plate_type,
            "confidence": confidence,
            "processing_time": processing_time
        }

    except Exception as e:
        print(f"è¯†åˆ«å¤±è´¥: {e}")
        return {
            "plate_number": "è¯†åˆ«å¤±è´¥",
            "plate_type": "æœªçŸ¥",
            "confidence": 0.0,
            "processing_time": 0.0
        }

# APIç«¯ç‚¹
@app.get("/", response_class=HTMLResponse)
async def root():
    """ä¸»é¡µ"""
    return f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</title>
        <meta charset="utf-8">
        <style>
            body {{ font-family: 'Microsoft YaHei', Arial, sans-serif; margin: 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; }}
            .container {{ max-width: 800px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); padding: 40px; text-align: center; }}
            h1 {{ color: #333; margin-bottom: 30px; font-size: 2.5em; }}
            .btn {{ display: inline-block; background: linear-gradient(45deg, #667eea, #764ba2); color: white; text-decoration: none; padding: 15px 30px; border-radius: 25px; margin: 10px; font-size: 1.1em; transition: all 0.3s ease; }}
            .btn:hover {{ transform: translateY(-2px); box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4); }}
            .info {{ background: #f8f9fa; padding: 20px; border-radius: 10px; margin: 20px 0; }}
            .status {{ padding: 10px; border-radius: 5px; margin: 10px 0; }}
            .status.success {{ background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš— è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</h1>
            <div class="info">
                <p>åŸºäºæ·±åº¦å­¦ä¹ çš„æ™ºèƒ½è½¦ç‰Œè¯†åˆ«è§£å†³æ–¹æ¡ˆ</p>
                <p>ä½¿ç”¨é«˜ç²¾åº¦æ¨¡å‹è¿›è¡Œè¯†åˆ«ï¼Œæ”¯æŒåŸå§‹è®­ç»ƒæƒé‡</p>
                <div class="status success">
                    ç³»ç»ŸçŠ¶æ€: è¿è¡Œæ­£å¸¸ | æ¨¡å‹: å·²åŠ è½½ | è®¾å¤‡: {device}
                </div>
            </div>
            <div>
                <a href="/web" class="btn">è¿›å…¥Webç•Œé¢</a>
                <a href="/docs" class="btn">APIæ–‡æ¡£</a>
                <a href="/test" class="btn">åŠŸèƒ½æµ‹è¯•</a>
            </div>
        </div>
    </body>
    </html>
    """

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "device": str(device),
        "model_type": "é«˜ç²¾åº¦ResNetæ¨¡å‹"
    }

@app.get("/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    return {
        "device": str(device),
        "model_loaded": model is not None,
        "supported_formats": ["jpg", "jpeg", "png", "bmp", "tiff"],
        "max_file_size": "10MB",
        "model_type": "é«˜ç²¾åº¦ResNetæ¨¡å‹",
        "num_chars": len(PLATE_CHARS),
        "num_plate_types": len(PLATE_TYPES)
    }

@app.post("/recognize", response_model=RecognitionResult)
async def recognize_plate_api(file: UploadFile = File(...)):
    """å•å¼ å›¾ç‰‡è¯†åˆ«"""
    try:
        # è¯»å–å›¾ç‰‡
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        # è¯†åˆ«è½¦ç‰Œ
        result = recognize_plate(image)

        return RecognitionResult(
            plate_number=result["plate_number"],
            plate_type=result["plate_type"],
            confidence=result["confidence"],
            processing_time=result["processing_time"]
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/recognize_batch")
async def recognize_batch_api(files: List[UploadFile] = File(...)):
    """æ‰¹é‡è¯†åˆ«"""
    results = []

    for file in files:
        try:
            contents = await file.read()
            image = Image.open(io.BytesIO(contents))

            result = recognize_plate(image)
            results.append({
                "filename": file.filename,
                "plate_number": result["plate_number"],
                "plate_type": result["plate_type"],
                "confidence": result["confidence"],
                "processing_time": result["processing_time"]
            })

        except Exception as e:
            results.append({
                "filename": file.filename,
                "error": str(e)
            })

    return {"results": results}

@app.get("/web", response_class=HTMLResponse)
async def web_interface():
    """Webç•Œé¢"""
    return """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { font-family: 'Microsoft YaHei', Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; }
            .container { max-width: 1200px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 10px 30px rgba(0,0,0,0.3); overflow: hidden; }
            .header { background: linear-gradient(45deg, #667eea, #764ba2); color: white; padding: 30px; text-align: center; }
            .header h1 { font-size: 2.5em; margin-bottom: 10px; }
            .main-content { padding: 40px; }
            .upload-section { border: 3px dashed #ddd; border-radius: 10px; padding: 40px; text-align: center; margin-bottom: 30px; }
            .upload-btn { background: linear-gradient(45deg, #667eea, #764ba2); color: white; border: none; padding: 15px 30px; border-radius: 25px; font-size: 1.1em; cursor: pointer; margin: 10px; }
            .file-input { display: none; }
            .preview-section { display: grid; grid-template-columns: 1fr 1fr; gap: 30px; margin-top: 30px; }
            .image-preview, .result-preview { background: #f8f9fa; border-radius: 10px; padding: 20px; text-align: center; }
            .plate-number { font-size: 2em; font-weight: bold; color: #667eea; text-align: center; padding: 15px; background: linear-gradient(45deg, #f0f4ff, #e8f0ff); border-radius: 10px; margin: 15px 0; }
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸš— è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</h1>
                <p>é«˜ç²¾åº¦è½¦ç‰Œè¯†åˆ«</p>
            </div>
            <div class="main-content">
                <div class="upload-section">
                    <h2>ğŸ“¤ ä¸Šä¼ å›¾ç‰‡è¿›è¡Œè¯†åˆ«</h2>
                    <button class="upload-btn" onclick="document.getElementById('fileInput').click()">é€‰æ‹©å›¾ç‰‡</button>
                    <input type="file" id="fileInput" class="file-input" accept="image/*" onchange="handleFile(this.files[0])">
                </div>
                <div class="preview-section" id="previewSection" style="display: none;">
                    <div class="image-preview">
                        <h3>ğŸ“· åŸå§‹å›¾ç‰‡</h3>
                        <img id="previewImage" alt="é¢„è§ˆå›¾ç‰‡" style="max-width: 100%; max-height: 300px;">
                    </div>
                    <div class="result-preview">
                        <h3>ğŸ¯ è¯†åˆ«ç»“æœ</h3>
                        <div class="plate-number" id="plateNumber">ç­‰å¾…è¯†åˆ«...</div>
                        <div><strong>è½¦ç‰Œç±»å‹:</strong> <span id="plateType">-</span></div>
                        <div><strong>ç½®ä¿¡åº¦:</strong> <span id="confidence">-</span></div>
                        <div><strong>å¤„ç†æ—¶é—´:</strong> <span id="processingTime">-</span></div>
                    </div>
                </div>
            </div>
        </div>

        <script>
        async function handleFile(file) {
            if (!file) return;

            const previewImage = document.getElementById('previewImage');
            const previewSection = document.getElementById('previewSection');

            // æ˜¾ç¤ºé¢„è§ˆ
            previewImage.src = URL.createObjectURL(file);
            previewSection.style.display = 'grid';

            // ä¸Šä¼ è¯†åˆ«
            const formData = new FormData();
            formData.append('file', file);

            try {
                const response = await fetch('/recognize', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (response.ok) {
                    document.getElementById('plateNumber').textContent = result.plate_number;
                    document.getElementById('plateType').textContent = result.plate_type;
                    document.getElementById('confidence').textContent = Math.round(result.confidence * 100) + '%';
                    document.getElementById('processingTime').textContent = result.processing_time.toFixed(2) + 'ms';
                } else {
                    alert('è¯†åˆ«å¤±è´¥: ' + result.detail);
                }
            } catch (error) {
                alert('ç½‘ç»œé”™è¯¯: ' + error.message);
            }
        }
        </script>
    </body>
    </html>
    """

# å¯åŠ¨æ—¶åŠ è½½æ¨¡å‹
@app.on_event("startup")
async def startup_event():
    """å¯åŠ¨äº‹ä»¶"""
    success = load_model()
    if not success:
        print("è­¦å‘Š: æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç³»ç»Ÿå°†ä½¿ç”¨éšæœºæƒé‡")

    print("è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿå¯åŠ¨å®Œæˆ")
    print("ç³»ç»Ÿè®¿é—®åœ°å€:")
    print("  - ä¸»é¡µ: http://localhost:8001")
    print("  - Webç•Œé¢: http://localhost:8001/web")
    print("  - APIæ–‡æ¡£: http://localhost:8001/docs")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)