#!/usr/bin/env python3
"""
ç”Ÿäº§çº§è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ - ä¼˜åŒ–æ£€æµ‹ç®—æ³•ï¼Œç¡®ä¿å‡†ç¡®è¯†åˆ«
"""

import os
import sys
import logging
import time
import json
import sqlite3
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from datetime import datetime
import io

import numpy as np
from PIL import Image
import cv2
import torch
import torch.nn as nn
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import uvicorn
from starlette.middleware.cors import CORSMiddleware

# å°è¯•å¯¼å…¥Tesseract
try:
    import pytesseract
    tesseract_available = True
    print("Tesseract OCRå¯ç”¨")
except ImportError:
    tesseract_available = False
    print("Tesseract OCRä¸å¯ç”¨")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–FastAPIåº”ç”¨
app = FastAPI(title="ç”Ÿäº§çº§è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ", version="2.0.0")

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®é™æ€æ–‡ä»¶
app.mount("/static", StaticFiles(directory="static"), name="static")

# è½¦ç‰Œçœä»½ç®€ç§°
plate_chars = "äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†"
plate_numbers = "0123456789"
plate_letters = "ABCDEFGHJKLMNPQRSTUVWXYZ"

class ProductionOCRRecognizer:
    """ç”Ÿäº§çº§OCRè¯†åˆ«å™¨"""

    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.tesseract_available = tesseract_available
        logger.info(f"åˆå§‹åŒ–ç”Ÿäº§çº§OCRè¯†åˆ«å™¨ï¼Œè®¾å¤‡: {self.device}")
        logger.info(f"Tesseractå¯ç”¨: {self.tesseract_available}")

    def enhance_image(self, image: np.ndarray) -> np.ndarray:
        """å›¾åƒå¢å¼º"""
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image

        # è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)

        # é™å™ª
        denoised = cv2.fastNlMeansDenoising(enhanced, None, 10, 7, 21)

        return denoised

    def detect_by_color(self, image: np.ndarray) -> List[np.ndarray]:
        """åŸºäºé¢œè‰²æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        # è“è‰²è½¦ç‰ŒèŒƒå›´
        lower_blue = np.array([100, 80, 46])
        upper_blue = np.array([124, 255, 255])

        # ç»¿è‰²è½¦ç‰ŒèŒƒå›´ï¼ˆæ–°èƒ½æºï¼‰
        lower_green = np.array([35, 80, 46])
        upper_green = np.array([77, 255, 255])

        # é»„è‰²è½¦ç‰ŒèŒƒå›´
        lower_yellow = np.array([20, 80, 46])
        upper_yellow = np.array([35, 255, 255])

        # æ£€æµ‹è“è‰²è½¦ç‰Œ
        blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)
        blue_result = cv2.bitwise_and(image, image, mask=blue_mask)

        # æ£€æµ‹ç»¿è‰²è½¦ç‰Œ
        green_mask = cv2.inRange(hsv, lower_green, upper_green)
        green_result = cv2.bitwise_and(image, image, mask=green_mask)

        # æ£€æµ‹é»„è‰²è½¦ç‰Œ
        yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
        yellow_result = cv2.bitwise_and(image, image, mask=yellow_mask)

        # åˆå¹¶ç»“æœ
        combined_mask = blue_mask | green_mask | yellow_mask
        combined_result = cv2.bitwise_and(image, image, mask=combined_mask)

        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(combined_result, cv2.COLOR_BGR2GRAY)

        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)

        # å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 5))
        morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 1000:
                continue

            # è·å–æœ€å°å¤–æ¥çŸ©å½¢
            rect = cv2.minAreaRect(contour)
            box = cv2.boxPoints(rect)
            box = np.int0(box)

            # è®¡ç®—å®½é«˜æ¯”
            width = max(rect[1][0], rect[1][1])
            height = min(rect[1][0], rect[1][1])
            aspect_ratio = width / height if height > 0 else 0

            if 2.0 <= aspect_ratio <= 5.5:
                # è·å–æ—‹è½¬åçš„è½¦ç‰ŒåŒºåŸŸ
                x, y, w, h = cv2.boundingRect(contour)
                plate_roi = image[y:y+h, x:x+w]

                if plate_roi.size > 0:
                    plates.append(plate_roi)

        return plates

    def detect_by_contours(self, image: np.ndarray, enhanced: np.ndarray) -> List[np.ndarray]:
        """åŸºäºè½®å»“æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(enhanced, 50, 150)

        # å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 5))
        closed = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)

        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 1000:
                continue

            # è®¡ç®—è¾¹ç•ŒçŸ©å½¢
            x, y, w, h = cv2.boundingRect(contour)

            # å®½é«˜æ¯”æ£€æŸ¥
            aspect_ratio = w / h
            if 1.5 <= aspect_ratio <= 6.0:
                plate_roi = image[y:y+h, x:x+w]
                if plate_roi.size > 0:
                    plates.append(plate_roi)

        return plates

    def detect_by_gradient(self, image: np.ndarray) -> List[np.ndarray]:
        """åŸºäºæ¢¯åº¦æ£€æµ‹è½¦ç‰Œ"""
        plates = []

        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # Sobelç®—å­
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)

        # è®¡ç®—æ¢¯åº¦å¹…å€¼
        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        gradient_magnitude = np.uint8(gradient_magnitude / gradient_magnitude.max() * 255)

        # äºŒå€¼åŒ–
        _, binary = cv2.threshold(gradient_magnitude, 50, 255, cv2.THRESH_BINARY)

        # å½¢æ€å­¦æ“ä½œ
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 3))
        morph = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

        # æŸ¥æ‰¾è½®å»“
        contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 800:
                continue

            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h

            if 1.5 <= aspect_ratio <= 6.0:
                plate_roi = image[y:y+h, x:x+w]
                if plate_roi.size > 0:
                    plates.append(plate_roi)

        return plates

    def extract_text_advanced(self, image: np.ndarray) -> str:
        """é«˜çº§æ–‡å­—æå–"""
        if not self.tesseract_available:
            return ""

        try:
            # å›¾åƒé¢„å¤„ç†
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # è°ƒæ•´å¤§å°
            height, width = gray.shape
            if width < 200:
                scale = 200 / width
                new_width = int(width * scale)
                new_height = int(height * scale)
                gray = cv2.resize(gray, (new_width, new_height))

            # è‡ªé€‚åº”é˜ˆå€¼
            binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)

            # é™å™ª
            kernel = np.ones((2, 2), np.uint8)
            binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

            # è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = Image.fromarray(binary)

            # é…ç½®Tesseract
            custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789äº¬æ´¥æ²ªæ¸å†€è±«äº‘è¾½é»‘æ¹˜çš–é²æ–°è‹æµ™èµ£é„‚æ¡‚ç”˜æ™‹è’™é™•å‰é—½è´µç²¤é’è—å·å®ç¼ä½¿é¢†'

            # æå–æ–‡å­—
            text = pytesseract.image_to_string(pil_image, config=custom_config)

            # æ¸…ç†ç»“æœ
            text = text.strip().replace('\n', '').replace('\r', '').replace(' ', '')

            return text

        except Exception as e:
            logger.error(f"é«˜çº§æ–‡å­—æå–å¤±è´¥: {e}")
            return ""

    def validate_plate_number(self, text: str) -> bool:
        """éªŒè¯è½¦ç‰Œå·ç """
        if not text or len(text) < 7 or len(text) > 9:
            return False

        # æ£€æŸ¥å­—ç¬¦æœ‰æ•ˆæ€§
        valid_chars = plate_chars + plate_numbers + plate_letters
        return all(char in valid_chars for char in text)

    def determine_plate_type(self, plate_number: str) -> str:
        """ç¡®å®šè½¦ç‰Œç±»å‹"""
        if not plate_number:
            return "æœªçŸ¥"

        # æ–°èƒ½æºè½¦ç‰Œ
        if len(plate_number) == 8:
            return "ç»¿ç‰Œ"

        if len(plate_number) == 7 and plate_number[1] in ['D', 'F']:
            return "ç»¿ç‰Œ"

        # é»„ç‰Œ
        if plate_number[1] in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M']:
            if plate_number.startswith('ä½¿'):
                return "ä½¿é¢†é¦†"
            return "é»„ç‰Œ"

        # é»˜è®¤è“ç‰Œ
        return "è“ç‰Œ"

    def calculate_confidence_score(self, text: str, image_quality: float) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦åˆ†æ•°"""
        if not text:
            return 0.0

        confidence = 0.3

        # é•¿åº¦æ£€æŸ¥
        if len(text) in [7, 8]:
            confidence += 0.2

        # æ ¼å¼æ£€æŸ¥
        if self.validate_plate_number(text):
            confidence += 0.2

        # é¦–å­—ç¬¦æ£€æŸ¥
        if text[0] in plate_chars:
            confidence += 0.1

        # ç¬¬äºŒå­—ç¬¦æ£€æŸ¥
        if text[1] in plate_letters:
            confidence += 0.1

        # å›¾åƒè´¨é‡
        confidence += image_quality * 0.1

        return min(confidence, 0.99)

    def recognize_license_plate(self, image: Image.Image, filename: str) -> Dict[str, Any]:
        """ä¸»è¯†åˆ«å‡½æ•°"""
        start_time = time.time()

        try:
            # è½¬æ¢ä¸ºOpenCVæ ¼å¼
            cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

            # å›¾åƒå¢å¼º
            enhanced = self.enhance_image(cv_image)

            # å¤šç§æ£€æµ‹æ–¹æ³•
            all_plates = []

            # æ–¹æ³•1ï¼šé¢œè‰²æ£€æµ‹
            color_plates = self.detect_by_color(cv_image)
            all_plates.extend([(plate, 'color') for plate in color_plates])

            # æ–¹æ³•2ï¼šè½®å»“æ£€æµ‹
            contour_plates = self.detect_by_contours(cv_image, enhanced)
            all_plates.extend([(plate, 'contour') for plate in contour_plates])

            # æ–¹æ³•3ï¼šæ¢¯åº¦æ£€æµ‹
            gradient_plates = self.detect_by_gradient(cv_image)
            all_plates.extend([(plate, 'gradient') for plate in gradient_plates])

            if not all_plates:
                return {
                    "plate_number": "æœªæ£€æµ‹åˆ°è½¦ç‰Œ",
                    "plate_type": "æœªçŸ¥",
                    "confidence": 0.0,
                    "processing_time": (time.time() - start_time) * 1000,
                    "success": False,
                    "method": "detection_failed",
                    "note": "æœªæ‰¾åˆ°è½¦ç‰ŒåŒºåŸŸ"
                }

            # å¯¹æ¯ä¸ªå€™é€‰è½¦ç‰Œè¿›è¡Œè¯†åˆ«
            best_result = None
            best_confidence = 0

            for plate_image, method in all_plates:
                # æå–æ–‡å­—
                text = self.extract_text_advanced(plate_image)

                if text and self.validate_plate_number(text):
                    # è®¡ç®—å›¾åƒè´¨é‡
                    gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY) if len(plate_image.shape) == 3 else plate_image
                    image_quality = cv2.Laplacian(gray, cv2.CV_64F).var() / 1000

                    # è®¡ç®—ç½®ä¿¡åº¦
                    confidence = self.calculate_confidence_score(text, image_quality)

                    if confidence > best_confidence:
                        best_confidence = confidence
                        best_result = {
                            "plate_number": text,
                            "plate_type": self.determine_plate_type(text),
                            "confidence": confidence,
                            "processing_time": (time.time() - start_time) * 1000,
                            "success": True,
                            "method": f"production_{method}",
                            "note": f"çœŸå®OCRè¯†åˆ«: {text}",
                            "detection_count": len(all_plates)
                        }

            if best_result:
                return best_result
            else:
                return {
                    "plate_number": "OCRè¯†åˆ«å¤±è´¥",
                    "plate_type": "æœªçŸ¥",
                    "confidence": 0.0,
                    "processing_time": (time.time() - start_time) * 1000,
                    "success": False,
                    "method": "ocr_failed",
                    "note": f"æ£€æµ‹åˆ°{len(all_plates)}ä¸ªå€™é€‰åŒºåŸŸï¼Œä½†OCRå¤±è´¥"
                }

        except Exception as e:
            logger.error(f"è¯†åˆ«å¤±è´¥: {e}")
            return {
                "plate_number": "å¤„ç†å¼‚å¸¸",
                "plate_type": "æœªçŸ¥",
                "confidence": 0.0,
                "processing_time": (time.time() - start_time) * 1000,
                "success": False,
                "method": "exception"
            }

# åˆå§‹åŒ–è¯†åˆ«å™¨
recognizer = ProductionOCRRecognizer()

# æ•°æ®åº“åˆå§‹åŒ–
def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        conn = sqlite3.connect('production_recognition_history.db')
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS recognition_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                plate_number TEXT NOT NULL,
                plate_type TEXT NOT NULL,
                confidence REAL NOT NULL,
                processing_time REAL NOT NULL,
                image_path TEXT,
                method TEXT,
                note TEXT,
                detection_count INTEGER,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        conn.commit()
        conn.close()
        logger.info("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")

# æ•°æ®æ¨¡å‹
class RecognitionResult(BaseModel):
    plate_number: str
    plate_type: str
    confidence: float
    processing_time: float
    success: bool

# ä¿å­˜å†å²è®°å½•
def save_to_history(result: Dict[str, Any], image_path: str = None):
    """ä¿å­˜è¯†åˆ«ç»“æœåˆ°æ•°æ®åº“"""
    try:
        conn = sqlite3.connect('production_recognition_history.db')
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO recognition_history
            (plate_number, plate_type, confidence, processing_time, image_path, method, note, detection_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            result['plate_number'],
            result['plate_type'],
            result['confidence'],
            result['processing_time'],
            image_path,
            result.get('method', 'unknown'),
            result.get('note', ''),
            result.get('detection_count', 0)
        ))

        conn.commit()
        conn.close()
    except Exception as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")

# APIç«¯ç‚¹
@app.get("/", response_class=HTMLResponse)
async def read_root():
    """ä¸»é¡µ"""
    return """
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ç”Ÿäº§çº§è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { font-family: Arial, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; display: flex; justify-content: center; align-items: center; }
            .container { background: white; padding: 2rem; border-radius: 20px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); max-width: 800px; width: 90%; }
            h1 { text-align: center; color: #333; margin-bottom: 2rem; font-size: 2.5rem; }
            .upload-section { margin-bottom: 2rem; text-align: center; }
            .file-input { display: none; }
            .file-label { display: inline-block; padding: 12px 24px; background: #4CAF50; color: white; border-radius: 8px; cursor: pointer; transition: background 0.3s; }
            .file-label:hover { background: #45a049; }
            .result { margin-top: 2rem; padding: 1rem; border-radius: 8px; background: #f5f5f5; display: none; }
            .result.show { display: block; }
            .success { background: #d4edda; color: #155724; border: 1px solid #c3e6cb; }
            .error { background: #f8d7da; color: #721c24; border: 1px solid #f5c6cb; }
            .status { text-align: center; margin-bottom: 1rem; }
            .status-indicator { display: inline-block; width: 12px; height: 12px; border-radius: 50%; margin-right: 8px; }
            .online { background: #4CAF50; }
            .offline { background: #f44336; }
            .info-box { background: #e3f2fd; border: 1px solid #bbdefb; border-radius: 8px; padding: 1rem; margin-bottom: 1rem; }
            .info-box h3 { color: #1976d2; margin-bottom: 0.5rem; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸš— ç”Ÿäº§çº§è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿ</h1>

            <div class="status">
                <span class="status-indicator online"></span>
                <span id="statusText">æœåŠ¡å™¨çŠ¶æ€: åœ¨çº¿</span>
            </div>

            <div class="info-box">
                <h3>ç³»ç»Ÿç‰¹ç‚¹</h3>
                <p>â€¢ å¤šç§æ£€æµ‹ç®—æ³•ï¼ˆé¢œè‰²ã€è½®å»“ã€æ¢¯åº¦ï¼‰</p>
                <p>â€¢ é«˜çº§å›¾åƒå¢å¼ºæŠ€æœ¯</p>
                <p>â€¢ çœŸå®OCRæ–‡å­—æå–</p>
                <p>â€¢ æ™ºèƒ½è½¦ç‰Œç±»å‹è¯†åˆ«</p>
                <p>â€¢ å·¥ç¨‹çº§å¯é æ€§</p>
            </div>

            <div class="upload-section">
                <input type="file" id="fileInput" class="file-input" accept="image/*" onchange="uploadFile(this)">
                <label for="fileInput" class="file-label">é€‰æ‹©å›¾ç‰‡è¿›è¡Œè¯†åˆ«</label>
            </div>

            <div id="result" class="result"></div>
        </div>

        <script>
            function uploadFile(input) {
                const file = input.files[0];
                if (!file) return;

                const formData = new FormData();
                formData.append('file', file);

                document.getElementById('result').innerHTML = '<div class="loading">æ­£åœ¨è¯†åˆ«ä¸­...</div>';
                document.getElementById('result').classList.add('show');

                fetch('/recognize', {
                    method: 'POST',
                    body: formData
                })
                .then(response => response.json())
                .then(data => {
                    displayResult(data);
                })
                .catch(error => {
                    document.getElementById('result').innerHTML = '<div class="error">è¯†åˆ«å¤±è´¥: ' + error.message + '</div>';
                });
            }

            function displayResult(data) {
                const resultDiv = document.getElementById('result');
                if (data.success) {
                    resultDiv.innerHTML = `
                        <div class="success">
                            <h3>è¯†åˆ«æˆåŠŸï¼</h3>
                            <p><strong>è½¦ç‰Œå·ç :</strong> ${data.plate_number}</p>
                            <p><strong>è½¦ç‰Œç±»å‹:</strong> ${data.plate_type}</p>
                            <p><strong>ç½®ä¿¡åº¦:</strong> ${(data.confidence * 100).toFixed(1)}%</p>
                            <p><strong>å¤„ç†æ—¶é—´:</strong> ${data.processing_time.toFixed(2)}ms</p>
                            <p><strong>è¯†åˆ«æ–¹æ³•:</strong> ${data.method}</p>
                            <p><strong>æ£€æµ‹æ•°é‡:</strong> ${data.detection_count || 0}</p>
                            <p><strong>å¤‡æ³¨:</strong> ${data.note}</p>
                        </div>
                    `;
                } else {
                    resultDiv.innerHTML = '<div class="error">è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•</div>';
                }
            }

            function checkServerStatus() {
                fetch('/health')
                    .then(response => response.json())
                    .then(data => {
                        document.getElementById('statusText').textContent = 'æœåŠ¡å™¨çŠ¶æ€: åœ¨çº¿';
                        document.querySelector('.status-indicator').className = 'status-indicator online';
                    })
                    .catch(error => {
                        document.getElementById('statusText').textContent = 'æœåŠ¡å™¨çŠ¶æ€: ç¦»çº¿';
                        document.querySelector('.status-indicator').className = 'status-indicator offline';
                    });
            }

            checkServerStatus();
            setInterval(checkServerStatus, 30000);
        </script>
    </body>
    </html>
    """

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "model_type": "ProductionOCRRecognizer",
        "device": "cpu",
        "tesseract_available": tesseract_available,
        "recognition_method": "production_ocr",
        "detection_methods": ["color", "contour", "gradient"]
    }

@app.post("/recognize", response_model=RecognitionResult)
async def recognize_plate(file: UploadFile = File(...)):
    """å•ä¸ªè½¦ç‰Œè¯†åˆ«"""
    try:
        start_time = time.time()

        # è¯»å–å›¾åƒ
        contents = await file.read()
        image = Image.open(io.BytesIO(contents))

        # è¿›è¡Œè¯†åˆ«
        result = recognizer.recognize_license_plate(image, file.filename)

        # ä¿å­˜åˆ°å†å²è®°å½•
        save_to_history(result)

        return result

    except Exception as e:
        logger.error(f"è¯†åˆ«å¤±è´¥: {e}")
        return {
            "plate_number": "å¤„ç†å¼‚å¸¸",
            "plate_type": "æœªçŸ¥",
            "confidence": 0.0,
            "processing_time": 20.0,
            "success": False
        }

@app.get("/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    try:
        conn = sqlite3.connect('production_recognition_history.db')
        cursor = conn.cursor()

        cursor.execute("SELECT COUNT(*) FROM recognition_history")
        total_count = cursor.fetchone()[0]

        cursor.execute("SELECT COUNT(*) FROM recognition_history WHERE confidence >= 0.5")
        successful_count = cursor.fetchone()[0]

        cursor.execute("SELECT AVG(confidence) FROM recognition_history")
        avg_confidence = cursor.fetchone()[0] or 0

        conn.close()

        return {
            "total_recognitions": total_count,
            "successful_recognitions": successful_count,
            "success_rate": (successful_count / total_count * 100) if total_count > 0 else 0,
            "average_confidence": avg_confidence
        }

    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return {
            "total_recognitions": 0,
            "successful_recognitions": 0,
            "success_rate": 0.0,
            "average_confidence": 0.0
        }

@app.get("/history")
async def get_history():
    """è·å–å†å²è®°å½•"""
    try:
        conn = sqlite3.connect('production_recognition_history.db')
        cursor = conn.cursor()

        cursor.execute('''
            SELECT plate_number, plate_type, confidence, processing_time, method, note, detection_count, timestamp
            FROM recognition_history
            ORDER BY timestamp DESC
            LIMIT 100
        ''')

        history = []
        for row in cursor.fetchall():
            history.append({
                "plate_number": row[0],
                "plate_type": row[1],
                "confidence": row[2],
                "processing_time": row[3],
                "method": row[4],
                "note": row[5],
                "detection_count": row[6],
                "timestamp": row[7]
            })

        conn.close()

        return {"history": history}

    except Exception as e:
        logger.error(f"è·å–å†å²è®°å½•å¤±è´¥: {e}")
        return {"history": []}

if __name__ == "__main__":
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()

    print("ç”Ÿäº§çº§è½¦ç‰Œè¯†åˆ«ç³»ç»Ÿå¯åŠ¨")
    print("ç‰¹ç‚¹:")
    print("- å¤šç§æ£€æµ‹ç®—æ³•ï¼ˆé¢œè‰²ã€è½®å»“ã€æ¢¯åº¦ï¼‰")
    print("- é«˜çº§å›¾åƒå¢å¼ºæŠ€æœ¯")
    print("- çœŸå®OCRæ–‡å­—æå–")
    print("- æ™ºèƒ½è½¦ç‰Œç±»å‹è¯†åˆ«")
    print("- å·¥ç¨‹çº§å¯é æ€§")
    print("=" * 50)

    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(app, host="0.0.0.0", port=8022, reload=False)